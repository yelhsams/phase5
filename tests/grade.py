#!/usr/bin/env python3

import subprocess
import tempfile
import os
from pathlib import Path

def run_command(cmd: list[str], timeout: int = 30, stdin_file: Path = None):
    """Run a command and return the result."""
    try:
        stdin_data = None
        if stdin_file and stdin_file.exists():
            with open(stdin_file, 'r') as f:
                stdin_data = f.read()
        return subprocess.run(
            cmd,
            input=stdin_data,
            capture_output=True,
            text=True,
            timeout=timeout,
        )
    except subprocess.TimeoutExpired:
        print(f"Command timed out after {timeout} seconds")
        return None
    except Exception as e:
        print(f"Command failed: {e}")
        return None

def run_lexer_test(test_file: Path) -> tuple[bool, str]:
    """Run a single lexer test and return (passed, message)."""
    expected_lex_file = test_file.with_suffix('.mit.lex')

    with tempfile.NamedTemporaryFile(mode='w', delete=False) as temp_file:
        command = ["./run.sh", "scan", str(test_file), "-o", temp_file.name]
        temp_file_path = temp_file.name
        result = run_command(command)

    if result is None:
        return False, "Test execution failed"

    try:
        if expected_lex_file.exists():
            try:
                with open(expected_lex_file, 'r') as expected, open(temp_file_path, 'r') as actual:
                    expected_content = expected.read()
                    actual_content = actual.read()

                passed = (expected_content.strip() == actual_content.strip())
                message = "Passed" if passed else "Failed - output doesn't match expected"

            finally:
                os.unlink(temp_file_path)

        else:
            passed = result.returncode != 0
            message = "Passed" if passed else f"Failed - expected error but got exit code {result.returncode}"

        return passed, message

    except Exception as e:
        return False, f"Test execution failed: {str(e)}"

def run_parser_test(test_file: Path) -> tuple[bool, str]:
    """Run a single parser test and return (passed, message)."""
    test_name = test_file.name

    command = ["./run.sh", "parse", str(test_file)]
    result = run_command(command)

    if result is None:
        return False, "Test execution failed"

    if "good" in test_name:
        passed = result.returncode == 0
        expected_behavior = "success"
    elif "bad" in test_name:
        passed = result.returncode != 0
        expected_behavior = "error"
    else:
        passed = False
        expected_behavior = "unknown"

    if passed:
        message = "Passed"
    else:
        message = f"Failed - expected {expected_behavior} but got exit code {result.returncode}"

    return passed, message

def run_compiler_test(test_file: Path) -> tuple[bool, str]:
    """Run a single compiler test and return (passed, message).

    This compiles .mit to .mitbc, runs the bytecode through VM, and compares
    the output with the .out file. For 'bad' tests, expects exit code 1 and
    error output matching .out. For other tests, expects exit code 0 and
    stdout matching .out.
    """
    test_name = test_file.name

    # Find expected output file (.out or .mit.out)
    expected_out_file = test_file.with_suffix('.out')
    if not expected_out_file.exists():
        expected_out_file = Path(str(test_file) + '.out')

    # Skip test if no expected output file exists
    if not expected_out_file.exists():
        return True, "Skipped - no expected .out file"

    # Check for memory limit file
    memlimit_file = test_file.with_suffix('.memlimit')
    mem_limit = None
    if memlimit_file.exists():
        try:
            with open(memlimit_file, 'r') as f:
                mem_limit = int(f.read().strip())
        except:
            pass

    # Check for input file
    input_file = test_file.with_suffix('.in')

    # Compile .mit to temp .mitbc
    with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.mitbc') as temp_file:
        compile_command = ["./run.sh", "compile", str(test_file), "-o", temp_file.name]
        temp_file_path = temp_file.name
        compile_result = run_command(compile_command)

    if compile_result is None:
        try:
            os.unlink(temp_file_path)
        except:
            pass
        return False, "Compilation timed out"

    # Check if compilation succeeded
    if compile_result.returncode != 0:
        try:
            os.unlink(temp_file_path)
        except:
            pass
        return False, f"Compilation failed with exit code {compile_result.returncode}\nStderr: {compile_result.stderr[:200]}"

    try:
        # Run generated bytecode through VM
        vm_command = ["./run.sh", "vm", temp_file_path]
        if mem_limit is not None:
            vm_command.extend(["-m", str(mem_limit)])

        vm_result = run_command(vm_command, timeout=30, stdin_file=input_file)

        if vm_result is None:
            return False, "VM execution timed out"

        # Determine if this is a "bad" test (expects runtime error)
        is_bad_test = "bad" in test_name.lower()

        if is_bad_test:
            # For bad tests: expect exit code 1
            if vm_result.returncode != 1:
                return False, f"Bad test expected exit code 1 but got {vm_result.returncode}"

            # Parse expected output: lines before exception are stdout, last exception line is stderr
            with open(expected_out_file, 'r') as f:
                expected_lines = f.read().strip().split('\n')

            # Known exception types
            exception_types = [
                'IllegalCastException', 'IllegalArithmeticException',
                'UninitializedVariableException', 'RuntimeException',
                'InsufficientStackException'
            ]

            # Find the exception line
            exception_line_idx = -1
            for i, line in enumerate(expected_lines):
                for exc_type in exception_types:
                    if line.strip().startswith(exc_type):
                        exception_line_idx = i
                        break
                if exception_line_idx >= 0:
                    break

            if exception_line_idx >= 0:
                expected_stdout_lines = expected_lines[:exception_line_idx]
                expected_exception = expected_lines[exception_line_idx]
            else:
                # No exception found, assume last line is exception
                expected_stdout_lines = expected_lines[:-1] if len(expected_lines) > 1 else []
                expected_exception = expected_lines[-1] if expected_lines else ""

            # Check actual stderr contains the exception type
            actual_stderr = vm_result.stderr.strip()
            exception_type = expected_exception.split(':')[0].strip() if expected_exception else ""

            if exception_type and exception_type not in actual_stderr:
                return False, f"Expected error containing '{exception_type}' but got:\n{actual_stderr[:200]}"

            # Optionally check stdout matches (if there's expected stdout before exception)
            if expected_stdout_lines:
                actual_stdout_lines = vm_result.stdout.strip().split('\n') if vm_result.stdout.strip() else []
                if expected_stdout_lines != actual_stdout_lines:
                    return False, f"Bad test stdout mismatch: expected {expected_stdout_lines} but got {actual_stdout_lines}"

            return True, "Passed"
        else:
            # For good tests: expect exit code 0
            if vm_result.returncode != 0:
                return False, f"Expected exit code 0 but got {vm_result.returncode}\nStderr: {vm_result.stderr[:200]}"

            # Compare stdout with expected output
            with open(expected_out_file, 'r') as f:
                expected_output = f.read()

            actual_output = vm_result.stdout

            # Normalize line endings and trailing whitespace
            expected_lines = expected_output.strip().split('\n') if expected_output.strip() else []
            actual_lines = actual_output.strip().split('\n') if actual_output.strip() else []

            if expected_lines == actual_lines:
                return True, "Passed"
            else:
                message = "Failed - output doesn't match expected"
                for i, (exp, act) in enumerate(zip(expected_lines, actual_lines)):
                    if exp != act:
                        message += f"\n    Line {i+1}: expected '{exp}' but got '{act}'"
                        break
                if len(expected_lines) != len(actual_lines):
                    message += f"\n    Expected {len(expected_lines)} lines but got {len(actual_lines)}"
                return False, message

    except Exception as e:
        return False, f"Test execution failed: {str(e)}"
    finally:
        try:
            os.unlink(temp_file_path)
        except:
            pass

def run_vm_test(test_file: Path) -> tuple[bool, str]:
    """Run a single VM test and return (passed, message).

    This runs the .mitbc file directly through VM and compares output with .out file.
    """
    test_name = test_file.name

    # Find expected output file
    expected_out_file = test_file.with_suffix('.out')
    if not expected_out_file.exists():
        expected_out_file = Path(str(test_file) + '.out')

    # Skip test if no expected output file exists
    if not expected_out_file.exists():
        return True, "Skipped - no expected .out file"

    # Check for memory limit file
    memlimit_file = test_file.with_suffix('.memlimit')
    mem_limit = None
    if memlimit_file.exists():
        try:
            with open(memlimit_file, 'r') as f:
                mem_limit = int(f.read().strip())
        except:
            pass

    # Look for .mitbc file
    mitbc_file = test_file.with_suffix('.mitbc')
    if not mitbc_file.exists():
        return True, "Skipped - no .mitbc file"

    # Run bytecode through VM
    vm_command = ["./run.sh", "vm", str(mitbc_file)]
    if mem_limit is not None:
        vm_command.extend(["-m", str(mem_limit)])

    result = run_command(vm_command, timeout=30)

    if result is None:
        return False, "VM execution timed out"

    # Determine if this is a "bad" test
    is_bad_test = "bad" in test_name.lower()

    if is_bad_test:
        # For bad tests: expect exit code 1
        if result.returncode != 1:
            return False, f"Bad test expected exit code 1 but got {result.returncode}"

        with open(expected_out_file, 'r') as f:
            expected_error = f.read().strip()

        actual_stderr = result.stderr.strip()
        if expected_error:
            exception_type = expected_error.split(':')[0].strip()
            if exception_type in actual_stderr:
                return True, "Passed"
            else:
                return False, f"Expected error containing '{exception_type}' but got:\n{actual_stderr[:200]}"
        else:
            return True, "Passed"
    else:
        # For good tests: expect exit code 0
        if result.returncode != 0:
            return False, f"Expected exit code 0 but got {result.returncode}\nStderr: {result.stderr[:200]}"

        with open(expected_out_file, 'r') as f:
            expected_output = f.read()

        actual_output = result.stdout

        expected_lines = expected_output.strip().split('\n') if expected_output.strip() else []
        actual_lines = actual_output.strip().split('\n') if actual_output.strip() else []

        if expected_lines == actual_lines:
            return True, "Passed"
        else:
            message = "Failed - output doesn't match expected"
            for i, (exp, act) in enumerate(zip(expected_lines, actual_lines)):
                if exp != act:
                    message += f"\n    Line {i+1}: expected '{exp}' but got '{act}'"
                    break
            if len(expected_lines) != len(actual_lines):
                message += f"\n    Expected {len(expected_lines)} lines but got {len(actual_lines)}"
            return False, message

def main():
    """Run all tests."""
    import argparse

    parser = argparse.ArgumentParser(description='Run MITScript tests')
    parser.add_argument('--phase', type=int, choices=[1, 2, 3, 4, 5], help='Test phase (1=lexer/parser, 2=interpreter, 4=compiler/vm, 5=compiler)')
    parser.add_argument('--test-dir', type=str, help='Test directory (default: auto-detect based on phase)')
    parser.add_argument('--test', type=str, help='Run specific test file')
    args = parser.parse_args()

    # If specific test is specified
    if args.test:
        test_file = Path(args.test)
        if not test_file.exists():
            print(f"Test file {test_file} not found")
            return

        print(f"Running single test: {test_file.name}")
        print()

        # Run all applicable tests
        if not args.phase or args.phase == 1:
            lexer_passed, lexer_msg = run_lexer_test(test_file)
            print(f"  Lexer: {lexer_msg}")

            parser_passed, parser_msg = run_parser_test(test_file)
            print(f"  Parser: {parser_msg}")

        if not args.phase or args.phase in [4, 5]:
            compiler_passed, compiler_msg = run_compiler_test(test_file)
            print(f"  Compiler: {compiler_msg}")

        return

    # Determine test directory
    if args.test_dir:
        test_dir = Path(args.test_dir)
    elif args.phase:
        test_dir = Path(f"tests/phase{args.phase}")
    else:
        # Try to auto-detect
        for phase in [5, 4, 3, 2, 1]:
            test_dir = Path(f"tests/phase{phase}")
            if test_dir.exists():
                args.phase = phase
                break
        else:
            print("No test directory found. Please specify --test-dir or --phase")
            return

    if not test_dir.exists():
        print(f"Test directory {test_dir} not found")
        return

    # Collect tests
    public_tests = list((test_dir / "public").glob("*.mit"))
    if not public_tests:
        public_tests = list(test_dir.glob("*.mit"))

    private_dir = test_dir / "private"
    private_tests = list(private_dir.glob("*.mit")) if private_dir.exists() else []

    all_tests = sorted(public_tests + private_tests)

    if not all_tests:
        print("No test files found")
        return

    print(f"Running tests from {test_dir}")
    print(f"Found {len(all_tests)} tests ({len(public_tests)} public, {len(private_tests)} private)")
    print()

    passed_tests = 0
    total_tests = 0

    for test_file in all_tests:
        print(f"Testing {test_file.name}:")

        # For phase 4/5, run compiler test
        if args.phase in [4, 5]:
            compiler_passed, compiler_msg = run_compiler_test(test_file)
            print(f"  Compiler: {compiler_msg}")
            if compiler_passed:
                passed_tests += 1
            total_tests += 1
        else:
            # Run lexer test
            lexer_passed, lexer_msg = run_lexer_test(test_file)
            print(f"  Lexer: {lexer_msg}")
            if lexer_passed:
                passed_tests += 1
            total_tests += 1

            # Run parser test
            parser_passed, parser_msg = run_parser_test(test_file)
            print(f"  Parser: {parser_msg}")
            if parser_passed:
                passed_tests += 1
            total_tests += 1

        print()

    print(f"Results: {passed_tests}/{total_tests} tests passed")
    print(f"Pass rate: {100.0 * passed_tests / total_tests:.1f}%")

    if passed_tests == total_tests:
        print("All tests passed!")
        return 0
    else:
        failed = total_tests - passed_tests
        print(f"{failed} test(s) failed.")
        return 1

if __name__ == "__main__":
    exit(main() or 0)
